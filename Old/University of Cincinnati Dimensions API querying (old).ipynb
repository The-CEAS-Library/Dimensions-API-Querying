{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Set up the dimensions API and required imports"
      ],
      "metadata": {
        "id": "twfe0rJzVMWK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4mLk3fxqigQ"
      },
      "source": [
        "### Step 1.1: Install the Dimensions API Client\n",
        "First, install the dimcli package to interact with the Dimensions API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0I4W1H4BH1CR"
      },
      "outputs": [],
      "source": [
        "!pip install dimcli -U --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This command installs the `dimcli` package, which provides the necessary tools to interact with the Dimensions database. The `-U` flag ensures that you install or update to the latest version, and the `--quiet` flag suppresses unnecessary output during installation."
      ],
      "metadata": {
        "id": "KdgaUiLtQRlq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmbctjkgqsxu"
      },
      "source": [
        "### Step 1.2: Import Required Libraries\n",
        "In this step, we will import the libraries and modules necessary for using the Dimensions API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Zxa5E8gKH3Go"
      },
      "outputs": [],
      "source": [
        "import dimcli\n",
        "from dimcli.utils import *\n",
        "import json\n",
        "import sys\n",
        "import pandas as pd\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `dimcli`: The library used to interact with the Dimensions API.\n",
        "- `json`: A library for parsing JSON data returned by the API.\n",
        "- `sys`: Used for handling system-specific parameters, like checking if the notebook is running in Google Colab.\n",
        "- `pandas`: A powerful data manipulation library, useful for handling and analyzing datasets."
      ],
      "metadata": {
        "id": "HeDsK-mnQabt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kej1FzU8q0QB"
      },
      "source": [
        "### Step 1.3: Log In to the Dimensions API\n",
        "To use the Dimensions API, you need to authenticate with your personal API key. In this step, you'll input your API key to log in."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sn5Wg3RH6Qu"
      },
      "outputs": [],
      "source": [
        "print(\"==\\nLogging in..\")\n",
        "# https://digital-science.github.io/dimcli/getting-started.html#authentication\n",
        "ENDPOINT = \"https://app.dimensions.ai\"\n",
        "if 'google.colab' in sys.modules:\n",
        "  import getpass\n",
        "  KEY = input(\"Input your API key for this session: \")\n",
        "  dimcli.login(key=KEY, endpoint=ENDPOINT)\n",
        "else:\n",
        "  KEY = \"\"\n",
        "  dimcli.login(key=KEY, endpoint=ENDPOINT)\n",
        "dsl = dimcli.Dsl()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The script checks if itâ€™s running in Google Colab using `sys.modules`.\n",
        "- If it is in Google Colab, it will prompt you to input your API key using `input()`. You can securely enter the key in Colab.\n",
        "- The `dimcli.login()` function authenticates with the API using the provided API key.\n",
        "- The `Dsl()` function creates an instance of the Dimensions API's Domain-Specific Language (DSL), which will be used to query the database."
      ],
      "metadata": {
        "id": "oCF6I_n9QrAX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ld2Y5i2aVI6"
      },
      "source": [
        "## Step 2: Load Faculty Data and Prepare Lists of Faculty Members\n",
        "In this step, we will read an Excel file containing the faculty roster and organize the data into dictionaries and lists that will be used for further analysis.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2.1: Create a Dictionary of DataFrame Objects\n",
        "We start by reading the Excel file that contains the faculty data. This file includes data for various years across different sheets."
      ],
      "metadata": {
        "id": "f3CgxO6OS8Ch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://raw.githubusercontent.com/The-CEAS-Library/Dimensions-API-Querying/master/Faculty%20Roster_Pillay%20Request_11.06.2024.xlsx' -O Faculty_Roster.xlsx"
      ],
      "metadata": {
        "id": "ligQt_nLc1Md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5q2UvLoZXJ8p"
      },
      "outputs": [],
      "source": [
        "faculty_data = pd.read_excel('Faculty_Roster.xlsx',['11.01.2018', '11.01.2019', '11.01.2020','11.01.2021','11.01.2022','11.01.2023','11.01.2024'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The `pd.read_excel()` function loads the Excel file `'Faculty Roster_Pillay Request_11.06.2024.xlsx'`.\n",
        "- The `['11.01.2018', '11.01.2019', ...]` argument specifies the list of sheet names to read from the Excel file, which correspond to different years.\n",
        "- The result is stored in `faculty_data`, a dictionary where each key is a year (e.g., `'11.01.2018'`), and the corresponding value is the data for that year in the form of a DataFrame."
      ],
      "metadata": {
        "id": "zWwDhrf7R0Q1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2.2: Initialize Lists for Names\n",
        "Next, we initialize empty lists to store the faculty members' names in different formats."
      ],
      "metadata": {
        "id": "EIR8JLlaTL_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists for names\n",
        "fullName, fName, lName, empNameAgg = [], [], [], []"
      ],
      "metadata": {
        "id": "R3W9ecNeTNO4"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `fullName`: A list for storing the full name of each faculty member (first and last).\n",
        "- `fName`: A list for storing the first names of faculty members.\n",
        "- `lName`: A list for storing the last names of faculty members.\n",
        "- `empNameAgg`: An aggregated list of all unique names across years."
      ],
      "metadata": {
        "id": "LaYJgsb7Tari"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2.3: Gather and Clean Employee Names by Year\n",
        "We now extract and clean the employee names for each year and store them in a dictionary. The names are cleaned by removing any periods, and the resulting list is sorted."
      ],
      "metadata": {
        "id": "FprdcIz3Tumu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of years for each date\n",
        "years = ['2018', '2019', '2020', '2021', '2022', '2023', '2024']\n",
        "\n",
        "# Gather and clean employee names by year\n",
        "empNames = {f'{year}': sorted(name.replace('.', '') for name in faculty_data[f'11.01.{year}']['Employee']) for year in years }"
      ],
      "metadata": {
        "id": "vwC9l0-3Twju"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `empNames`: A dictionary where each key is a year (e.g., `'2018'`), and the value is a sorted list of employee names after cleaning. The names are cleaned by removing periods, (`name.replace('.', '')`), because the database does not contain them in the names."
      ],
      "metadata": {
        "id": "GAgtg0mxT251"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 2.4: Aggregate All Names Across Years\n",
        "Next, we aggregate all unique faculty names from each year into one sorted list."
      ],
      "metadata": {
        "id": "9x0_NdznUHsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregate all cleaned names and sort unique entries\n",
        "empNameAgg = sorted(set(name for names in empNames.values() for name in names))"
      ],
      "metadata": {
        "id": "pqstIAu2UKdX"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This step flattens all the name lists across years and removes duplicates using `set()`.\n",
        "- The result is a sorted list of unique faculty member names stored in `empNameAgg`."
      ],
      "metadata": {
        "id": "lIX8tENjUJJs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2.5: Extract and Organize Name Components\n",
        "We will now extract and organize the first names, last names, and full names from all the sheets in `faculty_data`."
      ],
      "metadata": {
        "id": "z6BVTJRVUd9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract and organize name components across all sheets in faculty_data\n",
        "for sheet_data in faculty_data.values():\n",
        "    fName.extend(sheet_data['Preferred First Name'])\n",
        "    lName.extend(sheet_data['Preferred Last Name'])\n",
        "    fullName.extend(f\"{last} {first}\" for first, last in zip(sheet_data['Preferred First Name'], sheet_data['Preferred Last Name']))"
      ],
      "metadata": {
        "id": "cweii7G7UjPb"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- For each sheet in `faculty_data`, we extract the `'Preferred First Name'` and `'Preferred Last Name'` columns.\n",
        "- We then create the `fullName` list by combining first and last names into one string.\n",
        "- The `fName`, `lName`, and `fullName` lists are extended with the respective data from each sheet."
      ],
      "metadata": {
        "id": "q8CRK2-BUjhr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GNgO0GQaa4j"
      },
      "source": [
        "### Step 2.6: Remove Duplicates\n",
        "Finally, we remove any duplicates from the fullName and lName lists to ensure that each name appears only once."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicates from fullName and lName\n",
        "fullName = list(set(fullName))\n",
        "uniqueLN = list(set(lName))"
      ],
      "metadata": {
        "id": "E2SZbEPMD2z3"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `fullName` is converted into a set to remove duplicates, and then converted back to a list.\n",
        "- `uniqueLN` stores a list of unique last names."
      ],
      "metadata": {
        "id": "axD1DqidSJkM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2MNdrsLgVLL"
      },
      "source": [
        "## Step 3: Retrieve Researcher IDs from the Dimensions Database\n",
        "In this step, we will query the Dimensions database to retrieve information about researchers based on their last names and the research organization they belong to (in this case, the University of Cincinnati)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uriCNIHxrCZS"
      },
      "source": [
        "### Step 3.1: Define the Grid ID for the University of Cincinnati\n",
        "To query researchers at the University of Cincinnati, we first define the Grid ID for the university."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "he8UfdkCH8d8"
      },
      "outputs": [],
      "source": [
        "GRIDID = 'grid.24827.3b'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The `GRIDID` is the unique identifier for the University of Cincinnati in the Dimensions database. You will use this ID in the query to filter results by the university."
      ],
      "metadata": {
        "id": "uJMtcz8uWf24"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-NwUh7grN_z"
      },
      "source": [
        "### Step 3.2: Create the Query to Search for Researchers\n",
        "Next, we define the query that will search for researchers based on their last names and the university's Grid ID."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q = \"\"\"search researchers\n",
        "        where research_orgs = \"{}\"\n",
        "        and last_name in {}\n",
        "        return researchers\"\"\""
      ],
      "metadata": {
        "id": "H6_gY5O8Wptj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This query searches for researchers who belong to the research organization specified by the `GRIDID` and whose last names are in the `uniqueLN` list (which contains the cleaned and unique last names of faculty members)."
      ],
      "metadata": {
        "id": "l5uXts1cWyjj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3.3: Execute the Query and Retrieve the Results\n",
        "We execute the query and retrieve the results from the Dimensions API. The ```query_iterative``` method is used to fetch the data iteratively. This is because otherwise we can only grab up to 1000 results at a time."
      ],
      "metadata": {
        "id": "571hu44tXQNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run our query\n",
        "researchers_json = dsl.query_iterative(q.format(GRIDID, json.dumps(uniqueLN)))"
      ],
      "metadata": {
        "id": "Lbp8X4D5XezK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `q.format(GRIDID, json.dumps(uniqueLN))`: This formats the query by inserting the GRIDID and the list of last names (uniqueLN).\n",
        "- The query results are stored in the `researchers_json` variable."
      ],
      "metadata": {
        "id": "wlDg2jYfXijW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3.4: Convert the Results to a DataFrame\n",
        "The results returned by the query are in JSON format. To make them easier to work with, we convert them into a DataFrame using the `as_dataframe()` method."
      ],
      "metadata": {
        "id": "kF11VNRNXrpB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "OvyAgb4Ees1s"
      },
      "outputs": [],
      "source": [
        "#convert the information we retrieved into a DataFrame object\n",
        "researchers = researchers_json.as_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This creates a DataFrame called `researchers` that contains the details of the researchers, including their names, IDs, and other basic information."
      ],
      "metadata": {
        "id": "EFdWcJULXxxA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3.5: Create a Full Name Column\n",
        "To facilitate the matching of faculty members, we create a full_name column by combining the last_name and first_name columns. This allows us to directly compare full names between the faculty data and the researchers in the Dimensions database."
      ],
      "metadata": {
        "id": "wakY3tblQ8Wp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the full_name column\n",
        "researchers.insert(researchers.columns.get_loc('last_name') + 1,\n",
        "                   'full_name',\n",
        "                   researchers['last_name'] + ' ' + researchers['first_name'])"
      ],
      "metadata": {
        "id": "vYYZDSVcO44k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The `full_name` column is inserted after the `last_name` column.\n",
        "- The `full_name` is constructed by concatenating the `last_name` and `first_name` for each researcher, creating a single string that represents their full name."
      ],
      "metadata": {
        "id": "VgDE1mBiRHEV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3.6: Apply the Filter to Match Faculty Members\n",
        "After creating the `full_name` column, we proceed to filter the `researchers` DataFrame by comparing each researcherâ€™s full name to the faculty members' names. This step ensures that only the relevant faculty members are retained, accounting for potential variations in how names may be stored."
      ],
      "metadata": {
        "id": "0YkR2V3nX6ka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a mask to filter the DataFrame\n",
        "mask = researchers.apply(\n",
        "    lambda row: (\n",
        "        # Check that 'first_name' is a valid string before applying split\n",
        "        any(\n",
        "            re.search(rf\"^{row['full_name']}\\b.*$\", name)\n",
        "            for name in set(empNameAgg + fullName)\n",
        "        )\n",
        "    ),\n",
        "    axis=1\n",
        ")"
      ],
      "metadata": {
        "id": "PXUql2EGMs4x"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The `apply()` function iterates over each row in the ``researchers` DataFrame and applies the filter logic.\n",
        "- `re.search()` checks if the combination of the researcherâ€™s last and first name matches any name in `empNameAgg` or `fullName`.\n",
        "- Using `set(empNameAgg + fullName)` ensures that both lists are merged and duplicates are removed."
      ],
      "metadata": {
        "id": "qf29oXzQYAxn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3.7: Apply the Filter and Remove Duplicates\n",
        "Finally, we apply the filter to the DataFrame and drop any duplicate entries based on the researcher ID, last name, and first name."
      ],
      "metadata": {
        "id": "wMgUmaNsYItK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the DataFrame\n",
        "filtered_df = researchers[mask].drop_duplicates(subset=['id', 'last_name', 'first_name'], ignore_index=True)"
      ],
      "metadata": {
        "id": "_xwcAKE6YJQS"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `researchers[mask]` filters the rows that match the condition specified in the mask.\n",
        "- `drop_duplicates()` removes any rows with duplicate researcher IDs, ensuring that each researcher is listed only once.\n",
        "- `ignore_index=True` resets the index after dropping duplicates."
      ],
      "metadata": {
        "id": "G0pEco-bYKBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df"
      ],
      "metadata": {
        "id": "LR9DFxuzRvy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Retrieving and sorting information from our filtered dataframe"
      ],
      "metadata": {
        "id": "B0sn1kOGYba4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We can group the ids by the first and last name columns to combine most cases of multiple ids per a person"
      ],
      "metadata": {
        "id": "xCZ21L1to486"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "researchers_combined = filtered_df.groupby(['last_name', 'first_name', 'full_name'], as_index=False).agg({\n",
        "                                            'id': list  # Combine ids into a list\n",
        "                                          })"
      ],
      "metadata": {
        "id": "KlUA-bhiHark"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the result\n",
        "researchers_combined"
      ],
      "metadata": {
        "id": "wTI_0T1DwY3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By indexing or slicing with `.loc` and `.iloc`, we can combine rows of data manually that were missed or grab only the info associated with a single person (including the alternate names)."
      ],
      "metadata": {
        "id": "XciNS357V4Oi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Example for combining 2 rows that are the same person under different first names\n",
        "# Get the single row from the DataFrame\n",
        "single_researcher = researchers_combined.loc[[4], ['first_name', 'last_name', 'id']]\n",
        "\n",
        "# Append the new ID (from the 5th row) to the list in 'id'\n",
        "single_researcher['id'].iloc[0].extend(researchers_combined['id'].iloc[5])"
      ],
      "metadata": {
        "id": "b9N2tV3NaPAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the updated single_researcher\n",
        "single_researcher"
      ],
      "metadata": {
        "id": "UNzxj7c9wbRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some people have multiple researcher IDs so this needs manually verified that they are the same or different people\n"
      ],
      "metadata": {
        "id": "Wq5coGIGPvKy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r12p1jbFrv3p"
      },
      "source": [
        "## This retrieves information on the publications by the authors in the filtered_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All researcher ids"
      ],
      "metadata": {
        "id": "DEe93u73ZCBs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1eSJ0SEfx9I"
      },
      "outputs": [],
      "source": [
        "researchers_ids = filtered_df['id']\n",
        "researchers_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternatively create a list for the specific ids you wish to search"
      ],
      "metadata": {
        "id": "uNU2HiRFZDKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "r_id = list(itertools.chain.from_iterable(single_researcher['id']))\n",
        "r_id"
      ],
      "metadata": {
        "id": "s-d3FmzsQajO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AffUlsP6H-fx"
      },
      "outputs": [],
      "source": [
        "# no of researchers IDs per query: so to ensure we never hit the 1000 records limit per query\n",
        "\n",
        "# adjust the years here if you want to look at years different from the earlier list (2018-2024)\n",
        "#years = []\n",
        "\n",
        "q = \"\"\"search publications\n",
        "            where researchers.id in {}\n",
        "            and year in {}\n",
        "            return publications\n",
        "            limit 1000\"\"\"\n",
        "\n",
        "#change the value of r_id or use a different variable to adjust which person is being looked at\n",
        "data = dsl.query(q.format(json.dumps(r_id), json.dumps(years)))\n",
        "\n",
        "#data = dsl.query(q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UObsYPf0hiFm"
      },
      "outputs": [],
      "source": [
        "data_df = data.as_dataframe()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_df"
      ],
      "metadata": {
        "id": "CzTh_gUbVobR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kt9mz3riioyX"
      },
      "outputs": [],
      "source": [
        "data_df[[\"id\", \"title\", \"type\", \"year\"]]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "V4mLk3fxqigQ",
        "cmbctjkgqsxu",
        "0ld2Y5i2aVI6",
        "f3CgxO6OS8Ch",
        "EIR8JLlaTL_n",
        "FprdcIz3Tumu",
        "9x0_NdznUHsJ",
        "z6BVTJRVUd9N",
        "4GNgO0GQaa4j",
        "m2MNdrsLgVLL",
        "uriCNIHxrCZS",
        "q-NwUh7grN_z",
        "571hu44tXQNa",
        "kF11VNRNXrpB",
        "0YkR2V3nX6ka",
        "wMgUmaNsYItK"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
